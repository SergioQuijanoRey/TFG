{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231cd5e5-28e2-4d34-87a3-d921d2d89e38",
   "metadata": {},
   "source": [
    "# FG-Net\n",
    "\n",
    "- The purpose of this notebook is to provide the EDA done before trying to solve this dataset\n",
    "- Found this dataset in [this webpage](https://yanweifu.github.io/FG_NET_data/)\n",
    "- We have a [papers with code entry](https://paperswithcode.com/dataset/fg-net) where we can find how some people have used this dataset\n",
    "- From the *papers with code* entry, I find the **[following paper](https://arxiv.org/abs/1602.06149)**\n",
    "    - They propose a new dataset, Large Age-Gap dataset (LAG dataset)\n",
    "    - They talk about **LFW dataset**: is the most famous dataset where there are almost no constraints (lighting, pose...)\n",
    "    - But they constraint age, which is in what we are interested in!\n",
    "    - They talk about **FG-NET dataset** as one of the most famous datasets with aging gaps\n",
    "    - So I think it is **valuable to talk about this paper in my thesis**\n",
    "- *Papers with code* says that [this github repo](https://github.com/Hzzone/MTLFace) has the best model for the age-invariant recognition problem\n",
    "    - They have a related [paper](https://arxiv.org/abs/2103.01520)\n",
    "    - They use attention mechanisms\n",
    "    - They talk about age-invariant face recognition or _**AIFR**_\n",
    "    - They have a table with the results of different papers in this dataset, so **it can be interesting to talk about this paper in my thesis**\n",
    "    - They say that *FG-NET* is the most challenging dataset for *AIFR*\n",
    "    - They **describe precisely how testing is done**\n",
    "    - They say that **leave one method** is, iterate for each element of the dataset, query against the rest of the dataset, Rank@1\n",
    "    - They use **FG-Net only for validating**, they train on other huge dataset\n",
    "- Previous paper links to [this paper](https://arxiv.org/abs/1904.04972)\n",
    "    - They tackle AFAIR with a novel approach (I am not interested in that approach)\n",
    "    - They test against FG-Net with three metrics:\n",
    "        1. Leave one out\n",
    "        2. Mega Face Challenge 1: they test AFAIR models introducing a large amount of distractors\n",
    "        3. Mega Face Challenge 2\n",
    "- **NOTE**: some papers use the following protocol:\n",
    "    - They train on a bigger huge dataset\n",
    "    - Then, they use the whole FG-Net as evaluation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77db779-ffab-4cef-9b0a-0963f969c035",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da856e-6736-46be-a867-76909b9590e8",
   "metadata": {
    "id": "41da856e-6736-46be-a867-76909b9590e8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests, zipfile, io\n",
    "import itertools\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import lib.visualizations as visualizations\n",
    "import lib.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPwVGyBZIN3q",
   "metadata": {
    "id": "LPwVGyBZIN3q"
   },
   "source": [
    "# Global parameters of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3J1WEPR9IQDB",
   "metadata": {
    "id": "3J1WEPR9IQDB"
   },
   "outputs": [],
   "source": [
    "# Lib to define paths\n",
    "import os\n",
    "\n",
    "# - For ease of use, we are going to store all global parameters into a dict\n",
    "# - This way, we can pass this dict directly to wandb init, so we can keep track\n",
    "# of which parameters produced which output\n",
    "\n",
    "from typing import Dict, Union\n",
    "GLOBALS: Dict[str, Union[str, int, float, bool]] = dict()\n",
    "\n",
    "# Define if we are running the notebook in our computer (\"local\")\n",
    "# or in Google Colab (\"remote\")\n",
    "GLOBALS['RUNNING_ENV'] = \"local\"\n",
    "\n",
    "# Base path for the rest of paths defined in the notebook\n",
    "GLOBALS['BASE_PATH'] = \"./\" if GLOBALS['RUNNING_ENV'] == \"local\" else \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "\n",
    "# Path to our lib dir\n",
    "GLOBALS['LIB_PATH'] = os.path.join(GLOBALS['BASE_PATH'], \"lib\")\n",
    "\n",
    "# Path where we store training / test data\n",
    "GLOBALS['DATA_PATH'] = os.path.join(GLOBALS['BASE_PATH'], \"data/FG_NET\")\n",
    "\n",
    "# URL of the zipfile with the dataset\n",
    "GLOBALS['DATASET_URL'] = \"http://yanweifu.github.io/FG_NET_data/FGNET.zip\"\n",
    "\n",
    "# Dataset has images and metadata. Here we store the path to the img dir \n",
    "GLOBALS['IMAGE_DIR_PATH'] = os.path.join(GLOBALS['DATA_PATH'], \"FGNET/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "btdP3TCgJMDx",
   "metadata": {
    "id": "btdP3TCgJMDx"
   },
   "source": [
    "# Auth for Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rXPJXSQ0JNc2",
   "metadata": {
    "id": "rXPJXSQ0JNc2"
   },
   "outputs": [],
   "source": [
    "if GLOBALS['RUNNING_ENV'] == \"remote\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VK-X452lIQ46",
   "metadata": {
    "id": "VK-X452lIQ46"
   },
   "source": [
    "# Dataset downloading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcbcb0-8f63-43b6-b3cc-e71de37feb3d",
   "metadata": {
    "id": "14dcbcb0-8f63-43b6-b3cc-e71de37feb3d"
   },
   "outputs": [],
   "source": [
    "datasets.download_fg_dataset(\n",
    "    GLOBALS['DATA_PATH'],\n",
    "    GLOBALS['DATASET_URL'],\n",
    "    can_skip_download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ddb50-5fb3-4ec5-8acd-0046a679ba57",
   "metadata": {},
   "source": [
    "# Putting the data into a pytorch `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c2b77-54a9-45d4-9121-88d340f7aba3",
   "metadata": {
    "id": "176c2b77-54a9-45d4-9121-88d340f7aba3"
   },
   "outputs": [],
   "source": [
    "transform = T.transforms.Compose([\n",
    "    T.ToPILImage(),\n",
    "])\n",
    "dataset = datasets.FGDataset(path = GLOBALS['IMAGE_DIR_PATH'], transform = transform)\n",
    "dataset.set_exploration_mode(mode = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e34f1-f448-4882-afda-df8d9725d2a4",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d7de9-3900-4679-8492-d9aa525dbe0a",
   "metadata": {},
   "source": [
    "## Show some examples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MQ6sifNvNhZE",
   "metadata": {
    "id": "MQ6sifNvNhZE"
   },
   "outputs": [],
   "source": [
    "# Get a single element of the dataset\n",
    "\n",
    "for index in range(3):\n",
    "    \n",
    "    sample = dataset[index]\n",
    "    img = sample[\"image\"]\n",
    "    age = sample[\"age\"]\n",
    "    id = sample[\"id\"]\n",
    "    \n",
    "    print(f\"Id {id} at age {age}\")\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374a9bb-f68b-4fb8-ab7a-77354e416a6e",
   "metadata": {},
   "source": [
    "## Show all the images of a given individual, identified by its ID, sorted by their age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a03957-e166-438b-8107-5c3b669e3899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the id of the individual we want to identify\n",
    "id = 14\n",
    "\n",
    "# Select all the indixes corresponding to that individual\n",
    "id_indixes = [idx for idx, element in enumerate(dataset) if element[\"id\"] == id]\n",
    "\n",
    "# Sort the list of indixes by age\n",
    "id_indixes = sorted(\n",
    "    id_indixes, \n",
    "    key = lambda id: dataset[id][\"age\"],\n",
    "    reverse = False\n",
    ")\n",
    "\n",
    "# With the sorted list of indixes, now we can get the images \n",
    "# and also use the ages as the title for the subplots\n",
    "\n",
    "images = [\n",
    "    dataset[idx][\"image\"]\n",
    "    for idx in id_indixes\n",
    "]\n",
    "\n",
    "ages = [dataset[idx][\"age\"] for idx in id_indixes]\n",
    "titles = [f\"Age: {age}\" for age in ages]\n",
    "\n",
    "# Plot the images\n",
    "visualizations.PIL_show_images_with_titles_same_window(images, titles = ages, figsize = (20, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73232964-8972-4688-8f5f-e3c867db45b7",
   "metadata": {},
   "source": [
    "Checking different ID's shows us that the dataset generation seems to be properly implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a8ef7-057e-469e-960e-0ec982246067",
   "metadata": {},
   "source": [
    "## Show the shapes of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53986fc5-86f0-435a-b138-aa281b184d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    \n",
    "    # Get the image from the dataset\n",
    "    img = dataset[idx][\"image\"]\n",
    "\n",
    "    # Images are stored in PIL format, convert to pytorch tensors\n",
    "    transform = T.transforms.Compose([T.transforms.ToTensor()])\n",
    "    tensor = transform(img)\n",
    "\n",
    "    # And now we can query about its shape\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7621-7cd3-4b18-9c71-3c1ca603c55e",
   "metadata": {},
   "source": [
    "We have different shapes for the images, so some normalization has to be done. Also, some images are colored (3 channels) and other are in black & white (1 channel). So we should convert all the images to black and white."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8215f1-d31f-4ce6-8300-d74091183f1e",
   "metadata": {},
   "source": [
    "## Exploring the *images-per-person* distribution\n",
    "\n",
    "- One key aspect of the problem we are solving is the number of images per person\n",
    "- For example, when doing `P-K` sampling, if there are persons with less than `K` images, there might be a problem (we have some mechanisms to deal with that problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd910a2a-acec-486c-9b4b-1a4f9d838ab9",
   "metadata": {},
   "source": [
    "First, show the histogram of how many images per person there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R2qDSe8cVQQE",
   "metadata": {
    "id": "R2qDSe8cVQQE"
   },
   "outputs": [],
   "source": [
    "# Remember that `dataset.individuals` is a dict with keys the indixes of persons and with values\n",
    "# lists of ages (each age correspond to a stored image, thus there might be repeated ages if there\n",
    "# are more of one image for one concrete age)\n",
    "imgs_per_user = [len(individual_imgs) for individual_imgs in dataset.individuals.values()]\n",
    "\n",
    "# Now, plot the distribution of the ages\n",
    "visualizations.plot_histogram(\n",
    "    values = imgs_per_user,\n",
    "    num_bins = 20,\n",
    "    title = \"Images per user\",\n",
    "    xlabel = \"Images per user\",\n",
    "    ylabel = \"Number of instances\",\n",
    "    figsize = (10, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f0baf-5505-456b-824b-b9dd120d1b5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "There seems to be at least 6 images per person, and at most 18. The distribution seems to follow a normal distribution, but we are not interested in checking that assumption. Check the numbers putting the data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ee4f8-3da9-4ec9-8601-b1d2e7c4dc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_per_user_df = pd.DataFrame({\n",
    "    \"IDs\": dataset.individuals.keys(),\n",
    "    \"NÂº images\": imgs_per_user\n",
    "})\n",
    "imgs_per_user_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12234830-29c7-4f91-9d49-a7befc923d56",
   "metadata": {
    "tags": []
   },
   "source": [
    "So, in fact, we have at least 6 images per class, and 18 images per class at most! This is a huge improvement from the *LFW dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2870ff-2903-43b3-a588-572cfe15346f",
   "metadata": {},
   "source": [
    "## Exploring the age distribution\n",
    "\n",
    "- We have worked with the *LFW dataset*, but there was no variance in the age distribution (which is a key component in our problem)\n",
    "- So now study that age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5wpu8ZSe3W",
   "metadata": {
    "id": "6a5wpu8ZSe3W"
   },
   "outputs": [],
   "source": [
    "# Get a flat list with all the ages in the dataset\n",
    "ages = dataset.individuals.values()\n",
    "ages = list(itertools.chain(*ages))\n",
    "\n",
    "# Now, plot the histogram of the ages distribution\n",
    "visualizations.plot_histogram(\n",
    "    values = ages,\n",
    "    num_bins = 70,\n",
    "    title = \"Age distribution\",\n",
    "    xlabel = \"Age\",\n",
    "    ylabel = \"Number of instances\",\n",
    "    figsize = (10, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f81c8e-1005-44ce-a8f4-1ca19f48b33c",
   "metadata": {},
   "source": [
    "This histogram shows us a Skewed distribution. That is to say, we have more samples of young people than older people. This bias can be a problem if we want to use the trained model in real world enviroments, where the distribution can vary a lot! \n",
    "\n",
    "We can observe a great spike around the 20's. Lets explore further this distribution with a few basic metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc18926-78ee-4796-9ab9-78263719aa74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Mean age: {np.mean(ages)}\")\n",
    "print(f\"Min age: {min(ages)}\")\n",
    "print(f\"Max age: {max(ages)}\")\n",
    "print(f\"Most frequent age = {max(set(ages), key = ages.count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e9cb9-b6fe-4419-a8a1-e03a6286d3ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "The most frequent age, that we saw in the histogram, is in fact eighteen years. Ages range from 0 to 69 years. Lets get more detailed information using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab2035-aa26-4fa3-af4e-776c5edb687a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_ages = [min(age_list) for age_list in dataset.individuals.values()]\n",
    "max_ages = [max(age_list) for age_list in dataset.individuals.values()]\n",
    "\n",
    "ages_df = pd.DataFrame({\n",
    "    \"IDs\": dataset.individuals.keys(),\n",
    "    \"Min age\": min_ages,\n",
    "    \"Max age\": max_ages,\n",
    "})\n",
    "ages_df[\"Age range\"] = ages_df[\"Max age\"] - ages_df[\"Min age\"]\n",
    "\n",
    "ages_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd373546-25c9-4b85-a42e-a56b8bb3b8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ages_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb296d76-8087-4d32-bc36-e474e57a84f6",
   "metadata": {},
   "source": [
    "We can see that, at least, we have 11 years of difference among images of the same person. The mean age range is 27.80 years, which can make solving this task hard. But in the other hand, shows that this dataset is relevant for the problem that we are trying to solve. The biggest age range is 54 years.\n",
    "\n",
    "Let's see an histogram for the age range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae140b34-1552-4915-b456-b739846fbac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualizations.plot_histogram(\n",
    "    values = ages_df[\"Age range\"],\n",
    "    num_bins = 82,\n",
    "    title = \"Distribution of the age range\",\n",
    "    xlabel = \"Difference in years for the same person\",\n",
    "    ylabel = \"Frequency\",\n",
    "    figsize = (15, 10)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
