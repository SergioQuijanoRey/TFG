{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231cd5e5-28e2-4d34-87a3-d921d2d89e38",
   "metadata": {},
   "source": [
    "# CACD Dataset\n",
    "\n",
    "- The purpose of this notebook is to provide the EDA done before trying to solve this dataset\n",
    "- We are going to use this dataset to train and *FG-Net dataset* to validate. So we are really trying to solve the other dataset (which is really small for training) throught this huge dataset\n",
    "- [Papers with code entry](https://paperswithcode.com/dataset/cacd)\n",
    "- The dataset was introduced in the paper [Cross-Age Reference Coding for Age-Invariant Face Recognition and Retrieval](https://link.springer.com/chapter/10.1007/978-3-319-10599-4_49)\n",
    "    - They work with *Matlab*, and the dataset structure reflects that somehow (as they say in their website)\n",
    "- I think this is their [official website](https://bcsiriuschen.github.io/CARC/). In that website, they note:\n",
    "    - Celebrities with rank smaller or equal to five might have some noise\n",
    "    - The dataset might contain some duplicates\n",
    "    - Dataset thought for cross-age face recognition and retrivial. Year labels are rough and thus this dataset is not suitable for age-estimation problems\n",
    "    - So dataset seems to be a perfect fit for our needs\n",
    "    - They have prepared a **testing subset** with image pairs with half positives and half negatives\n",
    "- Dataset metadata (from their [website](https://bcsiriuschen.github.io/CARC/)):\n",
    "    - celebrityData - contains information of the 2,000 celebrities\n",
    "        - name - celebrity name\n",
    "        - identity - celebrity id\n",
    "        - birth - celebrity brith year\n",
    "        - rank - rank of the celebrity with same birth year in IMDB.com when the dataset was constructed\n",
    "        - lfw - whether the celebrity is in LFW dataset\n",
    "    - celebrityImageData - contains information of the face images\n",
    "        - age - estimated age of the celebrity\n",
    "        - identity - celebrity id\n",
    "        - year - estimated year of which the photo was taken\n",
    "        - feature - 75,520 dimension LBP feature extracted from 16 facial landmarks\n",
    "        - name - file name of the image\n",
    "- **IMPORTANT**: the dataset has been constructed by searching `<celebrity name> + <year between 2004 - 2013>`, so the max age difference for one person should be 8 years. In FG-Net we have age differences up to 54 years. So this might be a **PROBLEM**\n",
    "- **NOTE**: the 4.5GB dataset with all the metadata seems to be useless to our purposes. We can see in this [Google Colab Notebook](https://colab.research.google.com/drive/1X0NftH0Y1b2vL6ytztS2di7Iqfdine60?usp=sharing) that we are not going to use all of that metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77db779-ffab-4cef-9b0a-0963f969c035",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da856e-6736-46be-a867-76909b9590e8",
   "metadata": {
    "id": "41da856e-6736-46be-a867-76909b9590e8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests, zipfile, io\n",
    "import itertools\n",
    "from typing import Union, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import lib.visualizations as visualizations\n",
    "import lib.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LPwVGyBZIN3q",
   "metadata": {
    "id": "LPwVGyBZIN3q"
   },
   "source": [
    "# Global parameters of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3J1WEPR9IQDB",
   "metadata": {
    "id": "3J1WEPR9IQDB"
   },
   "outputs": [],
   "source": [
    "# Lib to define paths\n",
    "import os\n",
    "\n",
    "# - For ease of use, we are going to store all global parameters into a dict\n",
    "# - This way, we can pass this dict directly to wandb init, so we can keep track\n",
    "# of which parameters produced which output\n",
    "\n",
    "from typing import Dict, Union\n",
    "GLOBALS: Dict[str, Union[str, int, float, bool]] = dict()\n",
    "\n",
    "# Define if we are running the notebook in our computer (\"local\")\n",
    "# or in Google Colab (\"remote\")\n",
    "GLOBALS['RUNNING_ENV'] = \"local\"\n",
    "\n",
    "# Base path for the rest of paths defined in the notebook\n",
    "GLOBALS['BASE_PATH'] = \"./\" if GLOBALS['RUNNING_ENV'] == \"local\" else \"/content/drive/MyDrive/Colab Notebooks/\"\n",
    "\n",
    "# Path to our lib dir\n",
    "GLOBALS['LIB_PATH'] = os.path.join(GLOBALS['BASE_PATH'], \"lib\")\n",
    "\n",
    "# Path where we store training / test data\n",
    "GLOBALS['DATA_PATH'] = os.path.join(GLOBALS['BASE_PATH'], \"data/CACD\")\n",
    "\n",
    "# Images are stored in different folder, due to the fact that the extraction \n",
    "# method produces a new folder\n",
    "GLOBALS['IMAGE_DIR_PATH'] = os.path.join(GLOBALS['DATA_PATH'], \"CACD2000\")\n",
    "\n",
    "# URL of the zipfile with the dataset\n",
    "GLOBALS['DATASET_URL'] = \"https://drive.google.com/file/d/1hYIZadxcPG27Fo7mQln0Ey7uqw1DoBvM/view\"\n",
    "\n",
    "# Set some options for displaying better quality images\n",
    "\n",
    "# Font for the labels of the axes\n",
    "fontopts = {\n",
    "    'fontname': 'serif',\n",
    "    'fontsize': 16,\n",
    "}\n",
    "\n",
    "# Set higher DPI values\n",
    "%config InlineBackend.figure_format = 'retina'  # 'retina' or 'png2x'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "btdP3TCgJMDx",
   "metadata": {
    "id": "btdP3TCgJMDx"
   },
   "source": [
    "# Auth for Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rXPJXSQ0JNc2",
   "metadata": {
    "id": "rXPJXSQ0JNc2"
   },
   "outputs": [],
   "source": [
    "if GLOBALS['RUNNING_ENV'] == \"remote\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VK-X452lIQ46",
   "metadata": {
    "id": "VK-X452lIQ46",
    "tags": []
   },
   "source": [
    "# Dataset downloading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dcbcb0-8f63-43b6-b3cc-e71de37feb3d",
   "metadata": {
    "id": "14dcbcb0-8f63-43b6-b3cc-e71de37feb3d"
   },
   "outputs": [],
   "source": [
    "datasets.download_cacd_dataset(\n",
    "    GLOBALS['DATA_PATH'],\n",
    "    GLOBALS['DATASET_URL'],\n",
    "    can_skip_download = True,\n",
    "    can_skip_extraction = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ddb50-5fb3-4ec5-8acd-0046a679ba57",
   "metadata": {},
   "source": [
    "# Putting the data into a pytorch `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c2b77-54a9-45d4-9121-88d340f7aba3",
   "metadata": {
    "id": "176c2b77-54a9-45d4-9121-88d340f7aba3"
   },
   "outputs": [],
   "source": [
    "transform = T.transforms.Compose([\n",
    "    T.ToPILImage(),\n",
    "])\n",
    "dataset = datasets.CACDDataset(path = GLOBALS['IMAGE_DIR_PATH'], transform = transform)\n",
    "dataset.set_exploration_mode(mode = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e34f1-f448-4882-afda-df8d9725d2a4",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d7de9-3900-4679-8492-d9aa525dbe0a",
   "metadata": {},
   "source": [
    "## Show some examples of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MQ6sifNvNhZE",
   "metadata": {
    "id": "MQ6sifNvNhZE"
   },
   "outputs": [],
   "source": [
    "# Get a single element of the dataset\n",
    "\n",
    "for index in range(3):\n",
    "    \n",
    "    sample = dataset[index]\n",
    "    img = sample[\"image\"]\n",
    "    age = sample[\"age\"]\n",
    "    id = sample[\"id\"]\n",
    "    \n",
    "    print(f\"Id {id} at age {age}\")\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374a9bb-f68b-4fb8-ab7a-77354e416a6e",
   "metadata": {},
   "source": [
    "## Show all the images of a given individual, identified by its ID, sorted by their age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a03957-e166-438b-8107-5c3b669e3899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the id of the individual we want to identify\n",
    "id = 14\n",
    "\n",
    "# Select all the indixes corresponding to that individual\n",
    "id_indixes = [idx for idx, element in enumerate(dataset) if element[\"id\"] == id]\n",
    "\n",
    "# Sort the list of indixes by age\n",
    "id_indixes = sorted(\n",
    "    id_indixes, \n",
    "    key = lambda id: dataset[id][\"age\"],\n",
    "    reverse = False\n",
    ")\n",
    "\n",
    "# With the sorted list of indixes, now we can get the images \n",
    "# and also use the ages as the title for the subplots\n",
    "\n",
    "images = [\n",
    "    dataset[idx][\"image\"]\n",
    "    for idx in id_indixes\n",
    "]\n",
    "\n",
    "ages = [dataset[idx][\"age\"] for idx in id_indixes]\n",
    "titles = [f\"Age: {age}\" for age in ages]\n",
    "\n",
    "# Plot the images\n",
    "visualizations.PIL_show_images_with_titles_same_window(images, titles = ages, figsize = (20, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73232964-8972-4688-8f5f-e3c867db45b7",
   "metadata": {},
   "source": [
    "Checking different ID's shows us that the dataset generation seems to be properly implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a8ef7-057e-469e-960e-0ec982246067",
   "metadata": {},
   "source": [
    "## Show the shapes of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53986fc5-86f0-435a-b138-aa281b184d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    \n",
    "    # Get the image from the dataset\n",
    "    img = dataset[idx][\"image\"]\n",
    "\n",
    "    # Images are stored in PIL format, convert to pytorch tensors\n",
    "    transform = T.transforms.Compose([T.transforms.ToTensor()])\n",
    "    tensor = transform(img)\n",
    "\n",
    "    # And now we can query about its shape\n",
    "    print(tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7621-7cd3-4b18-9c71-3c1ca603c55e",
   "metadata": {},
   "source": [
    "All the images seems to have the shape. Also, they all seem to be in color (3 channels). So normalization here is not as critical as in the FG-Net dataset. However, FG-Net having different shapes and color schemes might be problematic (FG-Net might be much harder than this dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8215f1-d31f-4ce6-8300-d74091183f1e",
   "metadata": {},
   "source": [
    "## Exploring the *images-per-person* distribution\n",
    "\n",
    "- One key aspect of the problem we are solving is the number of images per person\n",
    "- For example, when doing `P-K` sampling, if there are persons with less than `K` images, there might be a problem (we have some mechanisms to deal with that problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd910a2a-acec-486c-9b4b-1a4f9d838ab9",
   "metadata": {},
   "source": [
    "First, show the histogram of how many images per person there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R2qDSe8cVQQE",
   "metadata": {
    "id": "R2qDSe8cVQQE"
   },
   "outputs": [],
   "source": [
    "# Remember that `dataset.individuals` is a dict with keys the indixes of persons and with values\n",
    "# lists of ages (each age correspond to a stored image, thus there might be repeated ages if there\n",
    "# are more of one image for one concrete age)\n",
    "imgs_per_user = [len(individual_imgs) for individual_imgs in dataset.individuals.values()]\n",
    "\n",
    "# Now, plot the distribution of the ages\n",
    "visualizations.plot_histogram(\n",
    "    values = imgs_per_user,\n",
    "    num_bins = 20,\n",
    "    title = \"Images per user\",\n",
    "    xlabel = \"Images per user\",\n",
    "    ylabel = \"Number of instances\",\n",
    "    figsize = (10, 8),\n",
    "    fontopts = fontopts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2f0baf-5505-456b-824b-b9dd120d1b5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "There seems to be at least more than 20 images per person, and at most 138 or 139. The data seems very likely to follow a normal distribution, but we are not interested in checking that assumption. Check the numbers putting the data into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ee4f8-3da9-4ec9-8601-b1d2e7c4dc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs_per_user_df = pd.DataFrame({\n",
    "    \"IDs\": dataset.individuals.keys(),\n",
    "    \"Nº images per user\": imgs_per_user\n",
    "})\n",
    "imgs_per_user_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12234830-29c7-4f91-9d49-a7befc923d56",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have at least 22 images per user, and at most 139. This might let us use bigger values of `K` in `P-K` sampling. But remember that in FG-Net we have at least 6 images per user and at most 18.\n",
    "\n",
    "Having bigger values than 18 should not produce python errors, as we are going to use FG-Net to validate with Rank@k, but if we want to use other metrics (such as Local Rank@k, it might matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2870ff-2903-43b3-a588-572cfe15346f",
   "metadata": {},
   "source": [
    "## Exploring the age distribution\n",
    "\n",
    "- We have worked with the *LFW dataset*, but there was no variance in the age distribution (which is a key component in our problem)\n",
    "- So now study that age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5wpu8ZSe3W",
   "metadata": {
    "id": "6a5wpu8ZSe3W"
   },
   "outputs": [],
   "source": [
    "# Get a flat list with all the ages in the dataset\n",
    "ages = dataset.individuals.values()\n",
    "ages = list(itertools.chain(*ages))\n",
    "\n",
    "# Now, plot the histogram of the ages distribution\n",
    "visualizations.plot_histogram(\n",
    "    values = ages,\n",
    "    num_bins = len(set(ages)),\n",
    "    title = \"Age distribution\",\n",
    "    xlabel = \"Age\",\n",
    "    ylabel = \"Number of instances\",\n",
    "    figsize = (10, 8),\n",
    "    fontopts = fontopts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f81c8e-1005-44ce-a8f4-1ca19f48b33c",
   "metadata": {},
   "source": [
    "FG-Net showed us an skewed distribution, with more samples of young ages. This time we have a more symetrical distribution. We don't have the same concentration of lower ages. \n",
    "\n",
    "This differences in distribution might be a problem in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc18926-78ee-4796-9ab9-78263719aa74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Mean age: {np.mean(ages)}\")\n",
    "print(f\"Min age: {min(ages)}\")\n",
    "print(f\"Max age: {max(ages)}\")\n",
    "print(f\"Most frequent age = {max(set(ages), key = ages.count)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e9cb9-b6fe-4419-a8a1-e03a6286d3ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lets compare this metrics with the CACD dataset ones:\n",
    "\n",
    "| Dataset | Mean Age | Min Age | Max Age | Most frequent age | \n",
    "|:---     | :---     | :---    | :---    | :---              | \n",
    "| FG-Net  | 15.84    | 0       | 69      | 18                | \n",
    "| CACD    | 38.03    | 14      | 62      | 37                | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83189895-63cf-4360-ab07-5d155a8db1c6",
   "metadata": {},
   "source": [
    "## Exploring the age range distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d2f66-2260-41a9-84c6-748c1c4445e2",
   "metadata": {},
   "source": [
    "First, compute the age range data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab2035-aa26-4fa3-af4e-776c5edb687a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_ages = [min(age_list) for age_list in dataset.individuals.values()]\n",
    "max_ages = [max(age_list) for age_list in dataset.individuals.values()]\n",
    "\n",
    "ages_df = pd.DataFrame({\n",
    "    \"IDs\": dataset.individuals.keys(),\n",
    "    \"Min age\": min_ages,\n",
    "    \"Max age\": max_ages,\n",
    "})\n",
    "ages_df[\"Age range\"] = ages_df[\"Max age\"] - ages_df[\"Min age\"]\n",
    "\n",
    "ages_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd373546-25c9-4b85-a42e-a56b8bb3b8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ages_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb296d76-8087-4d32-bc36-e474e57a84f6",
   "metadata": {},
   "source": [
    "We can see that, at least, we have 11 years of difference among images of the same person. The mean age range is 27.80 years, which can make solving this task hard. But in the other hand, shows that this dataset is relevant for the problem that we are trying to solve. The biggest age range is 54 years.\n",
    "\n",
    "Let's see an histogram for the age range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae140b34-1552-4915-b456-b739846fbac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualizations.plot_histogram(\n",
    "    values = ages_df[\"Age range\"],\n",
    "    num_bins = 1,\n",
    "    title = \"Distribution of the age range\",\n",
    "    xlabel = \"Difference in years for the same person\",\n",
    "    ylabel = \"Frequency\",\n",
    "    figsize = (15, 10),\n",
    "    fontopts = fontopts,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f449a9-5d2c-4c75-8be0-b9eaee45bffd",
   "metadata": {},
   "source": [
    "Show the age ranges of the individuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382296d-832e-4adc-b8b5-79d87e97e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_age_range(data: List[Tuple[int, int]]):\n",
    "    \"\"\"\n",
    "    Given a list with the following structure:\n",
    "        `[(lowest_age, highest_age), (lowest_age, highest_age), ...]`\n",
    "    plots, pear each individual, a vertical bar with their lowest and highest age.\n",
    "    \n",
    "    It's sorted first by lowest, then by highest\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort the data by lowest age values and then by highest age values\n",
    "    data.sort(key=lambda x: (x[0], x[1]))\n",
    "\n",
    "    # Initialize a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Calculate the width of each individual's age range\n",
    "    # Used for offsetting and getting non-overlapping lines\n",
    "    width = 200.0\n",
    "\n",
    "    # Create an array of x-values for each individual\n",
    "    x_values = np.arange(len(data))\n",
    "\n",
    "    # Loop through the sorted data and plot a line with circles for each individual\n",
    "    for i, (lowest, highest) in enumerate(data):\n",
    "        \n",
    "        # Midpoint age\n",
    "        mid_age = (lowest + highest) / 2 \n",
    "        \n",
    "        # Horizontaloffset to avoid overlapping\n",
    "        # Controled by width variable\n",
    "        offset = i * width \n",
    "        \n",
    "        # Vertical line\n",
    "        ax.plot([i + offset, i + offset], [lowest, highest], color='b', linewidth=2)  \n",
    "        \n",
    "        # Two circles\n",
    "        ax.plot(i + offset, lowest, 'bo', markersize=2)  \n",
    "        ax.plot(i + offset, highest, 'ro', markersize=2) \n",
    "\n",
    "    # Remove X-axis labels\n",
    "    ax.set_xticks([])\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Individual')\n",
    "    ax.set_ylabel('Age')\n",
    "    ax.set_title('Age Range per Individual (Sorted by Lowest Age, Secondary by Highest Age)')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19cbea-1c80-4a24-ba3c-a23d4893c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the age ranges\n",
    "age_lower_and_upper = []\n",
    "\n",
    "for el in dataset.individuals.values():\n",
    "    age_lower_and_upper.append((min(el), max(el)))\n",
    "\n",
    "# And use that data to plot\n",
    "plot_age_range(age_lower_and_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4547bb1-6096-4336-8ffc-a2d497cfdcb2",
   "metadata": {},
   "source": [
    "Almost all individuals have an age range of 9 years. See how many individuals have less than that age range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68ca62-a63a-40a8-ab05-6839496ba48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lower_ranges = [\n",
    "    age_range for age_range in list(ages_df['Age range'])\n",
    "    if age_range < 9\n",
    "]\n",
    "print(\"Nº of individuals having less than 9 years of age range: \", len(lower_ranges))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
