% !TeX root = ../libro.tex
% !TeX encoding = utf8
%
%*******************************************************
% Introducción
%*******************************************************

% \manualmark

% \markboth{\textsc{Introducción}}{\textsc{Introducción}}

\chapter{Resumen}

\textbf{Palabras clave}: Análisis Tensorial, Descomposición Tensorial \textit{CP}, Descomposición Tensorial \textit{HT}, Aprendizaje Automático, Aprendizaje Profundo, Visión por Computador, Redes Convolucionales, Reconocimiento Facial Invariante a la Edad, \textit{Triplet Loss}.

El presente Trabajo de Fin de Grado tiene dos \textbf{objetivos principales}. El primero de ellos, asociado a la parte de matemáticas, realizar una modelización de las redes neuronales convolucionales, profundas y no profundas, y estudiar la propiedad conocida comúnmente como \textit{depth efficiency}. El segundo, asociado a la parte de informática, resolver un problema en el ámbito del reconocimiento facial invariante a cambios en la edad, con especial interés en estudiar ciertas variantes sobre la función de pérdida \textit{Triplet Loss}, tratando de resolver algunos problemas asociados a su uso.

El uso de técnicas de aprendizaje automático basado en redes neuronales profundas ha crecido enormemente en los últimos años. Su buen rendimiento en ciertas tareas específicas ha sido demostrado de forma contundente. Sin embargo, este buen rendimiento \textbf{se justifica principalmente sobre la evidencia experimental}. A pesar de que se han llevado a cabo estudios teóricos para comprender las causas detrás de este alto rendimiento en la práctica, generalmente estos estudios se quedan rezagados frente a la evidencia empírica. Los trabajos que realizan un estudio para justificar la línea experimental suelen trabajar con modelizaciones matemáticas alejadas de los modelos comunes del aprendizaje profundo y los resultados suelen tratar sobre casos concretos en los que las redes profundas son claramente superiores a las redes no profundas.

Nos apoyaremos principalmente sobre la publicación \cite{matematicas:principal}, que introduce las modelizaciones matemáticas y resultados que estudiaremos. Nuestro trabajo en esta línea ha consistido en entender y estudiar dicha publicación, tratar de aclarar ciertos puntos oscuros y presentar un estudio teórico más extenso y ordenado. Este estudio es novedoso por dos motivos principales: la \textbf{modelización matemática de las redes neuronales es muy cercana a la realidad}, y el resultado sobre \textbf{\textit{depth efficiency} da información concreta sobre la cantidad de escenarios} en los que ocurre este fenómeno.

Expresaremos las funciones de puntuación que la red busca aprender en base a un tensor de coeficientes sobre un conjunto de funciones linealmente independiente y total. A partir de aquí, la modelización se basa en dos conocidas descomposiciones tensoriales, la descomposición \textit{CANDECOMP/PARAFAC} o \textit{CP} y la descomposición jerárquica \textit{Tucker} o \textit{HT}. Estas \textbf{modelizaciones tienen en cuenta las propiedades fundamentales de las redes convolucionales}: localidad de la convolución, coeficientes compartidos y operadores de \textit{pooling}.

Demostraremos \textbf{dos resultados centrales}. El primero nos muestra que, en el sentido de la medida de Lebesgue, casi todos los modelos no profundos necesitan un número exponencial de parámetros para implementar un modelo profundo. El segundo resultado añade que, de hecho, casi todos los modelos profundos no pueden ni siquiera ser aproximados por un modelo no profundo con menos de un número exponencial de parámetros.

En esta línea, \textbf{los objetivos de este estudio han sido alcanzados}. Hemos presentado y justificado una modelización matemática muy cercana a la realidad y hemos demostrado dos resultados que nos dan información exacta sobre en qué escenarios son más expresivas las redes profundas frente a las redes no profundas, y cuán frecuentemente sucede esto.

En la parte de informática hemos \textbf{trabajado un problema de reconocimiento facial invariante a la edad}. Además, ha sido de especial importancia el estudio de las técnicas introducidas en la publicación \cite{informatica:principal} aplicadas a esta tarea, enfoque que según nuestro conocimiento nunca se había explorado previamente. Dichas técnicas consisten en dos variantes \textit{online} sobre la función de pérdida \textit{Triplet Loss} \cite{informatica:principal}.  Además de los retos usuales de una solución basada en visión por computador, debemos añadir todos los \textbf{retos asociados a cómo el envejecimiento afecta las características faciales}.

En lo referente al estudio de las variantes \textit{online} de \textit{Triplet Loss}, gracias a la experimentación identificamos un problema en su diseño. Proponemos una solución original y validamos experimentalmente su gran eficacia. Una vez que disponemos de un método que genera buenos resultados gracias a esta solución, obtenemos un modelo que obtiene un valor de 0.6 en \textit{Rank@5 Accuracy} para el conjunto de datos \textit{CACD}. Además, nuestra solución permite mejorar distintas métricas entre 2 y 10 veces en \textit{MNIST} y entre 10 y 30 veces en \textit{CACD}.

Hemos descrito paso a paso el proceso que nos ha permitido encontrar esta solución original. La experimentación preliminar mostró resultados inusuales. Observamos estos mismos resultados en experimentos de terceros. Estudiando dicha experimentación preliminar localizamos un problema en el diseño de la función de pérdida. En base a esto, proponemos una solución original que validamos repitiendo los experimentos y obteniendo las mejoras significativas que ya hemos comentado.

Por lo tanto, consideramos que \textbf{hemos cumplido satisfactoriamente los objetivos planteados}. En primer lugar, hemos estudiado en profundidad las variantes \textit{online} de \textit{Triplet Loss}. Hemos detectado un problema en su diseño, propuesto una solución original y validado experimentalmente su gran eficacia. Sin nuestra solución estas variantes \textit{online} no producen buenos resultados y, por tanto, creemos que \textbf{nuestra propuesta tiene gran valor}. En segundo lugar, hemos obtenido un modelo que exhibe buenos resultados en la tarea del reconocimiento facial invariante a la edad. Para ello ha sido fundamental nuestra propuesta de solución.

\endinput
