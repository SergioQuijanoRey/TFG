% !TeX root = ../libro.tex
% !TeX encoding = utf8

\chapter{Introducción}

El objetivo de este trabajo, desde la perspectiva de las matemáticas, es analizar las redes neuronales profundas, basadas en convoluciones, y explicar por qué estas funcionan mejor que las redes neuronales no profundas, conocidas en la literatura como redes neuronales \textit{``shallow"}.

% TODO -- aqui habria que introducir algunas referencias de trabajos que esten
% analizando las redes neuronales pero que no tengan en cuenta estas particularidades
Este mejor comportamiento es muy conocido en la práctica, pero pocos son los trabajos que han analizado formalmente esta diferencia entre ambos tipos de redes. Además, en la mayoría de trabajos de este tipo, no se han tenido en cuenta propiedades fundamentales de las redes profundas ni de las redes convolucionales. Sin embargo, el estudio que hacemos en este trabajo tiene en cuenta principalmente:

\begin{itemize}
    \item La diferencia jerárquica entre ambos tipos de redes
    \item Propiedades fundamentales de las redes convolucionales. Esto es:
        \begin{itemize}
            \item Compartición de los coeficientes en las convoluciones
            \item Localidad de la operación de convolución
            \item Uso de la operación de \textit{pooling}
        \end{itemize}
\end{itemize}

El desarrollo que hacemos en el presente trabajo puede resumirse en los siguientes objetivos:

\begin{enumerate}
    \item Definir un espacio de hipótesis que queremos resolver con las redes neuronales
    \item Mostrar la equivalencia entre las redes neuronales que resuelven el espacio de hipótesis y descomposiciones de tensores. En concreto, con dos tipos de descomposiciones:
        \begin{enumerate}
            \item Descomposición \textit{CP}, que equivale al uso de redes no profundas
            \item Descomposición \textit{HT}, que equivale al uso de redes profundas
        \end{enumerate}
    \item Demostrar dos resultados centrales que nos muestran la superioridad de las redes profundas, en lo que se conoce como \textit{depth efficiency}, a través de las ya mencionadas descomposiciones tensoriales.
\end{enumerate}

Nos basaremos principalmente en el trabajo \cite{matematicas:principal}


\endinput
