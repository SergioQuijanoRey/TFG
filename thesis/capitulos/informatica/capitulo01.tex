% !TeX root = ../../libro.tex
% !TeX encoding = utf8

\chapter{Introducción}

% TODO -- estructura que le quiero dar al trabajo
% 1. Introduccion
% 1. Hablar del problema de retrieval de imagenes, y por qué este problema es relevante
% 1. Hablar del dataset que hemos empleado y de otros datasets que hemos considerado
% 1. Explicar el triplet loss, ventajas que se plantean en el paper de referencia
% 1. Desarrollo de Software
%     1. Explicar las herramientas usadas (entornos de python, librerias principales)
%     2. Explicar github CI CD
%     3. Explicar como accedemos al servidor
%     4. Explicar toda la estructura del codigo, patrones de diseños, sacarme partido aqui que es donde mas fuerte estoy
% 1. Hablar de la aproximacion al problema, iterativa, usando MNIST, LFW, luego CACD + FG-Net
%     - Esto se puede meter en algo asi como planificacion. Lo justifico diciendo que habia mucho codigo nuevo que implementar, y que para iterar de forma rapida iba resolviendo problemas cada vez mas complejos y mas pesados en lo que tamaño de datset se refiere
% 1. Analisis de los malos resultados
% 1. Proponer mejoras a estos problemas

% TODO -- tomar de referencia la guia de Pablo Mesejo: https://drive.google.com/drive/folders/1BGI7zUp0kiZ6ufCH1UlhzvcFPdZ5NFWN
% A partir de esta, importante:

% 1. Dar prioridad al resumen, introduccion (descripcion del problema, motivacion, objetivos) y las conclusiones (**"deben estar perfectas"**)
% 2. Introducir una figura de SCOPUS

Las \textbf{ideas principales} de este trabajo son dos. En primer lugar, resolver un problema de \textbf{reconocimiento facial invariante a cambios en la edad}, por sus siglas en inglés, \entrecomillado{AIFR}. En segundo lugar, introducir una nueva técnica de aprendizaje automático, que busca \textbf{solucionar los principales problemas que plantea el uso de la función de pérdida \entrecomillado{triplet loss}} \footnote{Esta nueva técnica se introduce en \cite{matematicas:principal}}. Introduce una forma de generar los \textit{batches} de triples de forma \textit{online}. Evitando así tener un paso separado en el ciclo de entrenamiento, dedicado únicamente a volver a generar de forma \textit{offline} nuevos \textit{batches} de triples. Y de paso, se consigue normalizar la dificultad que suponen estos conjuntos de triples.

Esta situación plantea una serie de \textbf{problemas}:

\begin{itemize}
    \item La nueva técnica de aprendizaje automático se plantea en un \textbf{ambiente completamente distinto} al de \textit{AIFR}. Por tanto, no disponemos de literatura en la que se expongan resultados obtenidos de aplicar estas técnicas a nuestro ámbito de trabajo
    \item Esta técnica cambia fundamentalmente la forma de generar \textit{batches} de datos. Y por tanto, modifica en esencia muchas partes primarias del proceso de aprendizaje. Por ejemplo, el ciclo de entrenamiento, el cálculo de métricas durante el entrenamiento, el acceso a los datos. Es por este motivo que hemos tenido que realizar \textbf{implementaciones personalizadas de casi todos estos elementos}, sin poder hacer uso de la mayoría de implementaciones que ofrecen las librerías de aprendizaje automático. Esto supone un \textbf{consumo de tiempo mayor}, teniendo en cuenta que hay que prestar \textbf{especial atención a la optimización y validación} mediante \textit{tests} de estos nuevos módulos
    \item Como comentaremos en \customref{ich:conclusiones}, este trabajo \textbf{no ha dado buenos resultados en la práctica}, comparado con otras técnicas más establecidas en el ámbito del \textit{AIFR}. Sin literatura que aplique nuestras nuevas técnicas en nuestro ámbito, tenemos que \textbf{basarnos en todo el trabajo realizado para estudiar el por qué} de este mal comportamiento.
\end{itemize}

\section{Descripción del problema}

\section{Motivación del problema}

\section{Descripción de la base de datos usada}

\section{Descripción de los objetivos}

\section{Planificación}

\section{}
