\chapter{Conclusiones} \label{ich:conclusiones}

El objetivo inicial del trabajo era el de estudiar dos variantes \textit{online} de \textit{Triplet Loss} para tratar de resolver una tarea de reconocimiento facial invariante a cambios en la edad. Los resultados que mostramos en la \tableref{} indican que estamos muy lejos de obtener un modelo competente. De hecho, los resultados obtenidos son tan malos que es imposible defenderlos. En este sentido no hemos cumplido con este objetivo inicial.

En base a esto, durante el desarrollo del presente Trabajo Fin de Grado incluimos tres nuevos objetivos. El primero, comprobar que estos resultados no son provocados por un fallo por nuestra parte, ya sea a la hora de implementar la base de código necesaria para la experimentación o a la hora de ejecutar las distintas ténicas sobre las que nos apoyamos. El segundo, una vez descartada esta posibilidad, identificar la raíz del problema y justificar esta explicación experimentalmente. En tercer lugar, proponer una solución original al problema y validar su eficacia.

A la hora de comprobar que los malos resultados no son provocados por un fallo nuestro, desarrollamos un amplio conjunto de \textit{tests} para validar nuestras implementaciones, como explicamos en \sectionref{}. Además, exploramos bases de código de terceros en las que encontramos los mismos problemas y malos resultados. Gracias a esto tenemos bastante seguridad de no ser los causantes de los resultados tan malos.

En \sectionref{} encontramos la raíz del mal comportamiento, un problema en la función de pérdida que provoca un comportamiento degenerado. Describimos la situación que se produce. Los procesos de entrenamiento y los resultados respaldan nuestra teoría. Los comportamientos inusuales que hemos visto durante la experimentación previa quedan perfectamente explicados ahora. Una vez identificado el problema proponemos una solución a este, que en cierta medida consideramos original. Validamos la efectividad de la propuesta con la experimentación realizada en \sectionref{} y \sectionref{}. Logramos mejoras significativas en las métricas que monitoreamos, incrementando su desempeño entre 2 y 30 veces, como muestran la \tableref{} y la \tableref{}. Aunque los resultados no sean competitivos con el estado del arte, nuestro objetivo ya ha dejado de ser este. En este sentido, los tres nuevos objetivos que nos proponemos durante el desarrollo del presente trabajo se han cumplido de forma satisfactoria.

% TODO -- comentar problemas que han alargado el trabajo. Desconfiar de nestra impl y no centrarnos en buscar la raiz del problema. Iterar sobre demasiadas bases de datos que luego no han aportado nada.

% TODO -- a partir de aqui tenemos las conclusiones antiguas
Durante el desarrollo del presente trabajo hemos adquirido un amplio conocimiento en ciertas áreas del aprendizaje automático, especialmente en el aprendizaje profundo. Este trabajo nos ha presentado una oportunidad única para estudiar en profundidad algunos conceptos como \textit{embeddings} semánticos, técnicas basadas en \textit{triplet loss} y algunas de sus variantes, ... El desarrollo de una amplia base de código nos ha permitido profundizar en la aplicación de patrones de diseño, y hemos aprendido en detalle el \textit{framework} de aprendizaje automático \textit{PyTorch}. Por tanto, ha resultado en una experiencia de aprendizaje bastante completa.

Nuestro análisis del estado del arte nos ha permitido identificar las tendencias más prometedoras en la resolución de la tarea de \textit{AIFR} planteada. Este análisis pone de manifiesto cuáles son las líneas más prometedoras de cara a realizar una investigación futura a partir del presente trabajo.

Hemos realizado une estudio detallado y satisfactorio  de los conjuntos de datos disponibles para resolver nuestra tarea. Hemos descrito los puntos fuertes y problemas de cada uno de los conjuntos presentados en dicho estudio. Prestamos especial atención al estudio del tamaño de los conjuntos de datos, la distribución de imágenes por individuo (fundamental a la hora de aplicar nuestras técnicas basadas en \textit{triplet loss} y \textit{P-K Sampling}) y la distribución de edad y rango de edad. Gracias a este análisis podemos considerar los pros y contras de cada uno de los \textit{datasets} disponibles, y con ello, realizar una toma de decisiones informada.

La implementación de una librería propia con las funciones necesarias para realizar nuestra experimentación ha sido lograda satisfactoriamente. La aplicación de la teoría estudiada a lo largo de la carrera en Matemáticas e Ingeniería Informática en patrones de diseño ha resultado en una arquitectura muy fácil de trabajar. Esto ha sido fundamental, puesto que nos ha permitido realizar iteraciones rápidas al enfrentarnos a los múltiples problemas que nos hemos ido encontrando a lo largo del desarrollo del trabajo.

Sin embargo, a pesar de nuestros esfuerzos en la implementación y experimentación en distintos conjuntos de datos, los resultados de la red neuronal han sido pésimos. No solo no logramos competir con los resultados del estado del arte, sino que tampoco conseguimos unos resultados lo suficientemente buenos para aplicar el modelo en situaciones prácticas. De haber sido así, al menos habríamos construido un modelo competente en cierta medida, pero mucho más ligero (tanto para entrenar como para realizar inferencias).

En base a los resultados tan malos obtenidos, nos planteamos la posibilidad de que estos resultados fuesen la consecuencia de haber introducido errores en nuestra amplia base de código. Esto motiva nuestro desarrollo de una extensa \textit{suite} de \textit{tests}. En base a esta validación, descartamos con cierto grado de confianza que el motivo de los malos resultados sea un error en la implementación. Esta validación es más relevante si tenemos en cuenta que no encontramos literatura científica en la que se resuelva nuestra tarea de \textit{AIFR} empleando \textit{triplet loss}, y mucho menos, las variantes concretas que hemos explorado en este trabajo. Por lo tanto, hemos tenido que justificar los malos resultados en base a la experiencia propia y en base a los experimentos presentados en este trabajo.

En consecuencia, algunos objetivos para proyectos futuros basados en el presente trabajo pueden incluir la publicación de la biblioteca desarrollada. Esto permitiría que otros investigadores experimentaran con las técnicas presentadas sin tener que realizar un esfuerzo significativo en la implementación, como ha sido nuestro caso. Por otro lado, sería conveniente explorar los modelos y técnicas utilizadas en los trabajos relativos al estado del arte. Como ya hemos comentado previamente, no consideramos que merezca la pena tratar de solucionar los problemas de las técnicas empleadas, sino que la línea más prometedora consiste en explorar el uso de modelos y técnicas mucho más potentes. Técnicas como el uso de redes generativas adversarias y modelos basados en mecanismos de atención. Dichos modelos y técnicas quedan fuera del alcance del grado en Ingeniería Informática y del presente trabajo.

En resumen, el presente trabajo ha sido una oportunidad única para trabajar en un problema real de aprendizaje automático, usando tecnologías estándar en la industria. Ha sido un proceso duro y frustrante, por todos los problemas encontrados a lo largo de todas las etapas del desarrollo y experimentación. Sin embargo, ha sido muy enriquecedor, y el aprendizaje que nos llevamos de todo el proceso es de un gran valor.

\todo{PMESEJO: echa de menos unas conclusiones numéricas}
% TODO -- estos son los comentarios
% En concreto, por ejemplo, en las conclusiones yo echo en falta conclusiones numéricas que indiquen, a nivel cuantitativo, si somos mejores o peores, y por cuánto, en relación al estado del arte. ¿Qué competidores hemos tenido en cuenta? ¿POr qué? ¿Sobre qué dataset los hemos comparado? ¿Cuáles son las principales conclusiones (take-home messages) queremos que se lleve quien se lea esto?
