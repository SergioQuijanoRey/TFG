\chapter{Conclusiones y futuras líneas de trabajo} \label{ich:conclusiones}

El objetivo inicial del trabajo era el de estudiar dos variantes \textit{online} de \textit{Triplet Loss} para tratar de resolver una tarea de reconocimiento facial invariante a cambios en la edad. Los resultados que mostramos en la \tableref{table:estado_del_arte_y_mi_modelo} indican que estamos muy lejos de obtener un modelo competente a la altura del estado del arte o de ser suficiente para utilizarlo en aplicaciones reales. Inicialmente, tras haber estudiado el estado del arte, esperábamos no conseguir resultados tan competentes como los que mostramos en la anterior tabla. Principalmente por no tener al alcance, tanto a nivel de conocimientos como a nivel de cómputo, técnicas avanzadas como modelos generativos adversarios y arquitecturas basadas en la atención. Además, el conjunto de datos usado para validar, \textit{FG-Net}, presenta una dificultad enorme, como comenta toda la literatura consultada al respecto. Pero los resultados obtenidos son tan malos que es imposible defenderlos. En este sentido no hemos cumplido con este objetivo inicial.

En base a esto, durante el desarrollo del presente Trabajo Fin de Grado, incluimos tres nuevos objetivos. El primero, comprobar que estos resultados no son provocados por un fallo por nuestra parte, ya sea a la hora de implementar la base de código necesaria para la experimentación o a la hora de ejecutar las distintas técnicas sobre las que nos apoyamos. El segundo, una vez descartada esta posibilidad, identificar la raíz del problema y justificar esta explicación experimentalmente. En tercer lugar, proponer una solución original al problema y validar su eficacia.

A la hora de comprobar que los malos resultados no son provocados por un fallo nuestro, desarrollamos un amplio conjunto de \textit{tests} para validar nuestras implementaciones, como explicamos en la \sectionref{isec:test_suite}. Además, en la \sectionref{isubsec:experiemntacion_base_codigo_externa}, exploramos bases de código de terceros en las que encontramos los mismos problemas y malos resultados. Gracias a esto tenemos bastante seguridad de no ser los causantes de los resultados tan malos.

A partir de aquí, en la \sectionref{isubsec:identificacion_problemas_propuesta_solucion} encontramos la raíz del mal comportamiento, un problema en la función de pérdida que provoca un comportamiento degenerado. Describimos la situación que se produce. La función de pérdida tiene un término de margen para evitar que la red colapse todas las entradas al vector nulo. Pero durante el entrenamiento aprende a colapsar todas las entradas a un centro de gravedad, es decir, un vector fijo no nulo del espacio. Los procesos de entrenamiento y los resultados que mostramos en la experimentación previa respaldan nuestra teoría. Los comportamientos inusuales que se muestran quedan perfectamente explicados ahora. Principalmente el hecho de que la función de pérdida se quede atascada exactamente en el valor del margen, independientemente de que modifiquemos este. Una vez identificado el problema proponemos una solución a este, que en cierta medida consideramos original. Consiste en introducir un termino en la función de pérdida que penaliza las distancias ancla-negatio pequeñas. Validamos la efectividad de la propuesta con la experimentación realizada en la \sectionref{isubsec:experimentacion_mnist_bien} y en la \sectionref{isubsec:experimentacion_cacd_bien}. Logramos mejoras significativas en las métricas que monitoreamos, incrementando su desempeño entre 2 y 30 veces, como muestran la \tableref{table:comparaciones_mnist_resultados} y la \tableref{table:comparaciones_cacd_resultados}. En concreto, para \textit{MNIST}, logramos mejoras de . Y para \textit{CACD}, logramos mejoras de . Aunque los resultados sobre \textit{CACD} no sean competitivos con el estado del arte, al estar obteniendo un \textit{Rank@1 accuracy} de , nuestro objetivo ya no era este. En este sentido, los tres nuevos objetivos que nos proponemos se han cumplido de forma satisfactoria.

Un punto importante a la hora de valorar el presente trabajo es que se ha extendido a lo largo del tiempo. Varios han sido los errores que han provocado esto, principalmente a la hora de reaccionar ante los resultados tan malos obtenidos durante la experimentación. Tras realizar un amplio conjunto de \textit{tests} que validan nuestra implementación y tras observar malos resultados sobre \textit{MNIST}, conjunto muy fácil de trabajar, deberíamos haber centrado nuestros esfuerzos en encontrar la raíz del problema en el diseño de la función de pérdida, interpretando adecuadamente los comportamientos exhibidos por los distintos procesos de entrenamiento. Sin embargo, nos centramos en otras tareas que consumieron mucho tiempo y aportaron poco valor. Iteramos sobre distintas bases de datos que apenas han aportado valor al final, como \textit{Labeled Faces in the Wild} o incluso \textit{FG-Net}, que a la hora de validar nuestra propuesta de solución ha sido relegada a un segundo plano. Perdemos mucho tiempo en optimizar la base de código, pensando que los malos resultados se deben a falta de tiempo en los procesos de entrenamiento. Podríamos haber visto que esto no iba a solucionar nada teniendo en cuenta los malos resultados sobre \textit{MNIST}, conjunto de datos sobre el que es muy rápido entrenar. Es decir, si hubiéramos confiado más en nuestra implementación y conjunto de \textit{tests}, centrando nuestros esfuerzos de forma adecuada en encontrar la raíz de problema, habríamos necesitado muchísimo menos tiempo para llevar a cabo el presente trabajo.

Además de la propuesta de solución original, durante el desarrollo del presente trabajo hemos adquirido un amplio conocimiento en ciertas áreas del aprendizaje automático, especialmente en el aprendizaje profundo. Este trabajo nos ha presentado una oportunidad única para estudiar en detalle algunos conceptos como \textit{embeddings} semánticos o distintas técnicas para entrenar redes siamesas. El desarrollo de una amplia base de código nos ha permitido profundizar en la aplicación de patrones de diseño y código limpio poniendo en práctica los aprendizajes obtenidos a lo largo del doble grado. Es destacable haber aprendido en detalle uno de los \textit{frameworks} de referencia en el campo del aprendizaje automático: \textit{PyTorch}. Por tanto, ha resultado en una experiencia de aprendizaje bastante completa.

En base a todo esto, surge una línea de trabajo futura muy interesante. Como hemos comentado, queda fuera del alcance del presente trabajo obtener un modelo realmente competente con el estado del arte tras proponer y validar nuestra solución original. Siguientes trabajos pueden buscar obtener dicho modelo competente tras haber solucionado los problemas con las dos variantes \textit{online} de \textit{Triplet Loss}, experimentando con otras arquitecturas de red y realizando una búsqueda de hiperparámetros en profundidad.
Adicionalmente, se puede probar y validar esta solución sobre otras áreas en las que se haya usado \textit{Triplet Loss} y en las que se hayan observado problemas parecidos a los que hemos enfrentado.

En resumen, el presente trabajo ha sido una oportunidad única para trabajar en un problema real de aprendizaje automático, usando tecnologías estándar en la industria. Ha sido un proceso duro y frustrante por todos los problemas encontrados en la experimentación. Sin embargo, ha sido muy enriquecedor, el haber encontrado la raíz última del problema y haber realizado una propuesta original y efectiva de solución ha sido muy gratificante, además del aprendizaje que nos llevamos de todo el proceso.
