\chapter{Conclusiones y futuras líneas de trabajo} \label{ich:conclusiones}

El objetivo inicial del trabajo era el de estudiar dos variantes \textit{online} de \textit{Triplet Loss} para tratar de resolver una tarea de reconocimiento facial invariante a cambios en la edad. Los resultados que mostramos en la \tableref{} indican que estamos muy lejos de obtener un modelo competente a la altura del estado del arte o de ser suficiente para utilizarlo en aplicaciones reales. De hecho, los resultados obtenidos son tan malos que es imposible defenderlos. En este sentido no hemos cumplido con este objetivo inicial.

En base a esto, durante el desarrollo del presente Trabajo Fin de Grado, incluimos tres nuevos objetivos. El primero, comprobar que estos resultados no son provocados por un fallo por nuestra parte, ya sea a la hora de implementar la base de código necesaria para la experimentación o a la hora de ejecutar las distintas técnicas sobre las que nos apoyamos. El segundo, una vez descartada esta posibilidad, identificar la raíz del problema y justificar esta explicación experimentalmente. En tercer lugar, proponer una solución original al problema y validar su eficacia.

A la hora de comprobar que los malos resultados no son provocados por un fallo nuestro, desarrollamos un amplio conjunto de \textit{tests} para validar nuestras implementaciones, como explicamos en la \sectionref{}. Además, en la \sectionref{}, exploramos bases de código de terceros en las que encontramos los mismos problemas y malos resultados. Gracias a esto tenemos bastante seguridad de no ser los causantes de los resultados tan malos.

A partir de aquí, en la \sectionref{} encontramos la raíz del mal comportamiento, un problema en la función de pérdida que provoca un comportamiento degenerado. Describimos la situación que se produce. La función de pérdida tiene un término de margen para evitar que la red colapse todas las entradas al vector nulo. Pero durante el entrenamiento aprende a colapsar todas las entradas a un centro de gravedad, es decir, un vector fijo no nulo del espacio. Los procesos de entrenamiento y los resultados que mostramos en la experimentación previa respaldan nuestra teoría. Los comportamientos inusuales que se muestran quedan perfectamente explicados ahora. Principalmente el hecho de que la función de pérdida se quede atascada exactamente en el valor del margen, independientemente de que modifiquemos este. Una vez identificado el problema proponemos una solución a este, que en cierta medida consideramos original. Validamos la efectividad de la propuesta con la experimentación realizada en \sectionref{} y \sectionref{}. Logramos mejoras significativas en las métricas que monitoreamos, incrementando su desempeño entre 2 y 30 veces, como muestran la \tableref{} y la \tableref{}. En concreto, para \textit{MNIST}, logramos mejoras de . Y para \textit{CACD}, logramos mejoras de . Aunque los resultados sobre \textit{CACD} no sean competitivos con el estado del arte, al estar obteniendo un \textit{Rank@1 accuracy} de , nuestro objetivo ya no era este. En este sentido, los tres nuevos objetivos que nos proponemos se han cumplido de forma satisfactoria.

Un punto importante a la hora de valorar el presente trabajo es que se ha extendido a lo largo del tiempo. Varios han sido los errores que han provocado esto, principalmente a la hora de reaccionar ante los resultados tan malos obtenidos durante la experimentación. Tras realizar un amplio conjunto de \textit{tests} que validan nuestra implementación y tras observar malos resultados sobre \textit{MNIST}, conjunto muy fácil de trabajar, deberíamos haber centrado nuestros esfuerzos en encontrar la raíz del problema en el diseño de la función de pérdida, interpretando adecuadamente los comportamientos exhibidos por los distintos procesos de entrenamiento. Sin embargo, nos centramos en otras tareas que consumieron mucho tiempo y aportaron poco valor. Iteramos sobre distintas bases de datos que apenas han aportado valor al final, como \textit{Labeled Faces in the Wild} o incluso \textit{FG-Net}, que a la hora de validar nuestra propuesta de solución ha sido relegada a un segundo plano. Perdemos mucho tiempo en optimizar la base de código, pensando que los malos resultados se deben a falta de tiempo en los procesos de entrenamiento. Podríamos haber visto que esto no iba a solucionar nada teniendo en cuenta los malos resultados sobre \textit{MNIST}, conjunto de datos sobre el que es muy rápido entrenar. Es decir, si hubiéramos confiado más en nuestra implementación y conjunto de \textit{tests}, centrando nuestros esfuerzos de forma adecuada en encontrar la raíz de problema, habríamos necesitado muchísimo menos tiempo para llevar a cabo el presente trabajo.

% TODO -- comentar problemas que han alargado el trabajo. Desconfiar de nestra impl y no centrarnos en buscar la raiz del problema. Iterar sobre demasiadas bases de datos que luego no han aportado nada.

% TODO -- a partir de aqui tenemos las conclusiones antiguas
Durante el desarrollo del presente trabajo hemos adquirido un amplio conocimiento en ciertas áreas del aprendizaje automático, especialmente en el aprendizaje profundo. Este trabajo nos ha presentado una oportunidad única para estudiar en profundidad algunos conceptos como \textit{embeddings} semánticos, técnicas basadas en \textit{triplet loss} y algunas de sus variantes, ... El desarrollo de una amplia base de código nos ha permitido profundizar en la aplicación de patrones de diseño, y hemos aprendido en detalle el \textit{framework} de aprendizaje automático \textit{PyTorch}. Por tanto, ha resultado en una experiencia de aprendizaje bastante completa.

Nuestro análisis del estado del arte nos ha permitido identificar las tendencias más prometedoras en la resolución de la tarea de \textit{AIFR} planteada. Este análisis pone de manifiesto cuáles son las líneas más prometedoras de cara a realizar una investigación futura a partir del presente trabajo.

Hemos realizado une estudio detallado y satisfactorio  de los conjuntos de datos disponibles para resolver nuestra tarea. Hemos descrito los puntos fuertes y problemas de cada uno de los conjuntos presentados en dicho estudio. Prestamos especial atención al estudio del tamaño de los conjuntos de datos, la distribución de imágenes por individuo (fundamental a la hora de aplicar nuestras técnicas basadas en \textit{triplet loss} y \textit{P-K Sampling}) y la distribución de edad y rango de edad. Gracias a este análisis podemos considerar los pros y contras de cada uno de los \textit{datasets} disponibles, y con ello, realizar una toma de decisiones informada.

La implementación de una librería propia con las funciones necesarias para realizar nuestra experimentación ha sido lograda satisfactoriamente. La aplicación de la teoría estudiada a lo largo de la carrera en Matemáticas e Ingeniería Informática en patrones de diseño ha resultado en una arquitectura muy fácil de trabajar. Esto ha sido fundamental, puesto que nos ha permitido realizar iteraciones rápidas al enfrentarnos a los múltiples problemas que nos hemos ido encontrando a lo largo del desarrollo del trabajo.

Sin embargo, a pesar de nuestros esfuerzos en la implementación y experimentación en distintos conjuntos de datos, los resultados de la red neuronal han sido pésimos. No solo no logramos competir con los resultados del estado del arte, sino que tampoco conseguimos unos resultados lo suficientemente buenos para aplicar el modelo en situaciones prácticas. De haber sido así, al menos habríamos construido un modelo competente en cierta medida, pero mucho más ligero (tanto para entrenar como para realizar inferencias).

En base a los resultados tan malos obtenidos, nos planteamos la posibilidad de que estos resultados fuesen la consecuencia de haber introducido errores en nuestra amplia base de código. Esto motiva nuestro desarrollo de una extensa \textit{suite} de \textit{tests}. En base a esta validación, descartamos con cierto grado de confianza que el motivo de los malos resultados sea un error en la implementación. Esta validación es más relevante si tenemos en cuenta que no encontramos literatura científica en la que se resuelva nuestra tarea de \textit{AIFR} empleando \textit{triplet loss}, y mucho menos, las variantes concretas que hemos explorado en este trabajo. Por lo tanto, hemos tenido que justificar los malos resultados en base a la experiencia propia y en base a los experimentos presentados en este trabajo.

En consecuencia, algunos objetivos para proyectos futuros basados en el presente trabajo pueden incluir la publicación de la biblioteca desarrollada. Esto permitiría que otros investigadores experimentaran con las técnicas presentadas sin tener que realizar un esfuerzo significativo en la implementación, como ha sido nuestro caso. Por otro lado, sería conveniente explorar los modelos y técnicas utilizadas en los trabajos relativos al estado del arte. Como ya hemos comentado previamente, no consideramos que merezca la pena tratar de solucionar los problemas de las técnicas empleadas, sino que la línea más prometedora consiste en explorar el uso de modelos y técnicas mucho más potentes. Técnicas como el uso de redes generativas adversarias y modelos basados en mecanismos de atención. Dichos modelos y técnicas quedan fuera del alcance del grado en Ingeniería Informática y del presente trabajo.

En resumen, el presente trabajo ha sido una oportunidad única para trabajar en un problema real de aprendizaje automático, usando tecnologías estándar en la industria. Ha sido un proceso duro y frustrante, por todos los problemas encontrados a lo largo de todas las etapas del desarrollo y experimentación. Sin embargo, ha sido muy enriquecedor, y el aprendizaje que nos llevamos de todo el proceso es de un gran valor.

\todo{PMESEJO: echa de menos unas conclusiones numéricas}
% TODO -- estos son los comentarios
% En concreto, por ejemplo, en las conclusiones yo echo en falta conclusiones numéricas que indiquen, a nivel cuantitativo, si somos mejores o peores, y por cuánto, en relación al estado del arte. ¿Qué competidores hemos tenido en cuenta? ¿POr qué? ¿Sobre qué dataset los hemos comparado? ¿Cuáles son las principales conclusiones (take-home messages) queremos que se lleve quien se lea esto?
